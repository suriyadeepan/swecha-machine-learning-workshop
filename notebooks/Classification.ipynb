{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data are the results of a chemical analysis of wines grown in the same region in Italy\n",
    "but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. \n",
    "\n",
    "I think that the initial data set had around 30 variables, but for some reason I only have the 13 dimensional version. I had a list of what the 30 or so variables were, but a.) I lost it, and b.), I would not know which 13 variables are included in the set. \n",
    "\n",
    "The attributes are (dontated by Riccardo Leardi, riclea '@' anchem.unige.it ) \n",
    "\n",
    "1. Alcohol \n",
    "2. Malic acid \n",
    "3. Ash \n",
    "4. Alcalinity of ash \n",
    "5. Magnesium \n",
    "6. Total phenols \n",
    "7. Flavanoids \n",
    "8. Nonflavanoid phenols \n",
    "9. Proanthocyanins \n",
    "10. Color intensity \n",
    "11. Hue \n",
    "12. OD280/OD315 of diluted wines \n",
    "13. Proline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x, data_y = helper.read_wine_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.787     ,  0.186     ,  0.45500001,  0.278     ,  0.28299999,\n",
       "        0.57599998,  0.41999999,  0.245     ,  0.495     ,  0.292     ,\n",
       "        0.45500001,  0.85000002,  0.54000002], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_x, train_data_y = data_x[:150], data_y[:150]\n",
    "test_data_x, test_data_y = data_x[150:], data_y[150:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a classifier, that maps the feature vector to a class of wine (1, 2 or 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = data_x.shape[-1]\n",
    "num_classes = data_y.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x_ = tf.placeholder(shape=[num_features], dtype=tf.float32, name='x')\n",
    "y_ = tf.placeholder(shape=[num_classes], dtype=tf.float32, name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* parameters/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.get_variable(dtype=tf.float32, shape=[num_features, num_classes], name='W',\n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.get_variable(dtype=tf.float32, shape=[num_classes], name='b',\n",
    "                    initializer=tf.constant_initializer(0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(tf.reshape(x_, [1, num_features]), W) + b\n",
    "probs = tf.nn.softmax(logits)\n",
    "prediction = tf.argmax(probs, axis=1)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  [ 0.03437493]\n",
      "loss :  [ 0.02117923]\n",
      "loss :  [ 0.01562519]\n",
      "loss :  [ 0.01247798]\n",
      "loss :  [ 0.01042869]\n",
      "loss :  [ 0.00897978]\n",
      "loss :  [ 0.00789723]\n",
      "loss :  [ 0.00705567]\n",
      "loss :  [ 0.00638163]\n",
      "loss :  [ 0.0058339]\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(epochs):\n",
    "    avg_loss = 0.\n",
    "    for batch_x, batch_y in zip(train_data_x, train_data_y):\n",
    "        _, loss_value = sess.run([train_op, loss], feed_dict = {\n",
    "            x_ : batch_x,\n",
    "            y_ : batch_y\n",
    "        })\n",
    "        avg_loss += loss_value\n",
    "    if (i and i%100 == 0) or i == epochs-1:\n",
    "        print('loss : ', avg_loss/len(train_data_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Tasting Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Wine Class : 1\n",
      "Predicted Wine Class :  1\n",
      "\t with confidence of [ 99.99989319]%\n"
     ]
    }
   ],
   "source": [
    "j = np.random.randint(0, len(test_data_x)-1)\n",
    "test_xj, test_yj = test_data_x[j], test_data_y[j]\n",
    "predicted_value, confidence = sess.run([prediction, probs], feed_dict= {\n",
    "    x_ : test_xj\n",
    "})\n",
    "print('Real Wine Class :', np.argmax(test_yj))\n",
    "print('Predicted Wine Class : ', predicted_value[0])\n",
    "print('\\t with confidence of {}%'.format(confidence[0][predicted_value]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
